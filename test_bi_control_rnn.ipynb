{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "Installing numpy>=1.21.0...\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-2.4.0-cp312-cp312-macosx_14_0_x86_64.whl.metadata (6.6 kB)\n",
      "Downloading numpy-2.4.0-cp312-cp312-macosx_14_0_x86_64.whl (6.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-2.4.0\n",
      "Installing pandas>=1.3.0...\n",
      "Collecting pandas>=1.3.0\n",
      "  Downloading pandas-2.3.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (91 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./.venv/lib/python3.12/site-packages (from pandas>=1.3.0) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas>=1.3.0) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.3.0)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.3.0)\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.0) (1.17.0)\n",
      "Downloading pandas-2.3.3-cp312-cp312-macosx_10_13_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [pandas]2m2/3\u001b[0m [pandas]\n",
      "\u001b[1A\u001b[2KSuccessfully installed pandas-2.3.3 pytz-2025.2 tzdata-2025.3\n",
      "Installing scipy>=1.7.0...\n",
      "Collecting scipy>=1.7.0\n",
      "  Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: numpy<2.6,>=1.25.2 in ./.venv/lib/python3.12/site-packages (from scipy>=1.7.0) (2.4.0)\n",
      "Downloading scipy-1.16.3-cp312-cp312-macosx_14_0_x86_64.whl (23.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.16.3\n",
      "Installing jax>=0.4.0...\n",
      "Collecting jax>=0.4.0\n",
      "  Downloading jax-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading jax-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading jax-0.7.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading jax-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading jax-0.5.2-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
      "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.4.0)\n",
      "  Downloading jaxlib-0.4.38-cp312-cp312-macosx_10_14_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting ml_dtypes>=0.4.0 (from jax>=0.4.0)\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: numpy>=1.24 in ./.venv/lib/python3.12/site-packages (from jax>=0.4.0) (2.4.0)\n",
      "Collecting opt_einsum (from jax>=0.4.0)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: scipy>=1.10 in ./.venv/lib/python3.12/site-packages (from jax>=0.4.0) (1.16.3)\n",
      "Downloading jax-0.4.38-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jaxlib-0.4.38-cp312-cp312-macosx_10_14_x86_64.whl (99.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-macosx_10_13_universal2.whl (676 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m676.9/676.9 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Installing collected packages: opt_einsum, ml_dtypes, jaxlib, jax\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [jax]\u001b[32m3/4\u001b[0m [jax]ib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed jax-0.4.38 jaxlib-0.4.38 ml_dtypes-0.5.4 opt_einsum-3.4.0\n",
      "✓ jaxlib>=0.4.0 already installed\n",
      "Installing dm-haiku>=0.0.10...\n",
      "Collecting dm-haiku>=0.0.10\n",
      "  Downloading dm_haiku-0.0.16-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting absl-py>=0.7.1 (from dm-haiku>=0.0.10)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting jmp>=0.0.2 (from dm-haiku>=0.0.10)\n",
      "  Downloading jmp-0.0.4-py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.12/site-packages (from dm-haiku>=0.0.10) (2.4.0)\n",
      "Collecting tabulate>=0.8.9 (from dm-haiku>=0.0.10)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Downloading dm_haiku-0.0.16-py3-none-any.whl (374 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading jmp-0.0.4-py3-none-any.whl (18 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate, jmp, absl-py, dm-haiku\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [dm-haiku]3/4\u001b[0m [dm-haiku]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 dm-haiku-0.0.16 jmp-0.0.4 tabulate-0.9.0\n",
      "Installing optax>=0.1.4...\n",
      "Collecting optax>=0.1.4\n",
      "  Downloading optax-0.2.6-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in ./.venv/lib/python3.12/site-packages (from optax>=0.1.4) (2.3.1)\n",
      "Collecting chex>=0.1.87 (from optax>=0.1.4)\n",
      "  Downloading chex-0.1.91-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting jax>=0.5.3 (from optax>=0.1.4)\n",
      "  Using cached jax-0.8.2-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is looking at multiple versions of optax to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting optax>=0.1.4\n",
      "  Downloading optax-0.2.5-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: jax>=0.4.27 in ./.venv/lib/python3.12/site-packages (from optax>=0.1.4) (0.4.38)\n",
      "Requirement already satisfied: jaxlib>=0.4.27 in ./.venv/lib/python3.12/site-packages (from optax>=0.1.4) (0.4.38)\n",
      "Requirement already satisfied: numpy>=1.18.0 in ./.venv/lib/python3.12/site-packages (from optax>=0.1.4) (2.4.0)\n",
      "Collecting typing_extensions>=4.15.0 (from chex>=0.1.87->optax>=0.1.4)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting chex>=0.1.87 (from optax>=0.1.4)\n",
      "  Downloading chex-0.1.90-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting setuptools (from chex>=0.1.87->optax>=0.1.4)\n",
      "  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting toolz>=0.9.0 (from chex>=0.1.87->optax>=0.1.4)\n",
      "  Downloading toolz-1.1.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in ./.venv/lib/python3.12/site-packages (from jax>=0.4.27->optax>=0.1.4) (0.5.4)\n",
      "Requirement already satisfied: opt_einsum in ./.venv/lib/python3.12/site-packages (from jax>=0.4.27->optax>=0.1.4) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in ./.venv/lib/python3.12/site-packages (from jax>=0.4.27->optax>=0.1.4) (1.16.3)\n",
      "Downloading optax-0.2.5-py3-none-any.whl (354 kB)\n",
      "Downloading chex-0.1.90-py3-none-any.whl (101 kB)\n",
      "Downloading toolz-1.1.0-py3-none-any.whl (58 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: typing_extensions, toolz, setuptools, chex, optax\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [optax]32m4/5\u001b[0m [optax]ools]\n",
      "\u001b[1A\u001b[2KSuccessfully installed chex-0.1.90 optax-0.2.5 setuptools-80.9.0 toolz-1.1.0 typing_extensions-4.15.0\n",
      "Installing matplotlib>=3.5.0...\n",
      "Collecting matplotlib>=3.5.0\n",
      "  Downloading matplotlib-3.10.8-cp312-cp312-macosx_10_13_x86_64.whl.metadata (52 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.5.0)\n",
      "  Downloading contourpy-1.3.3-cp312-cp312-macosx_10_13_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.5.0)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.5.0)\n",
      "  Downloading fonttools-4.61.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (114 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.5.0)\n",
      "  Downloading kiwisolver-1.4.9-cp312-cp312-macosx_10_13_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0) (2.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0) (25.0)\n",
      "Collecting pillow>=8 (from matplotlib>=3.5.0)\n",
      "  Downloading pillow-12.0.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib>=3.5.0)\n",
      "  Downloading pyparsing-3.3.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.5.0) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.5.0) (1.17.0)\n",
      "Downloading matplotlib-3.10.8-cp312-cp312-macosx_10_13_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp312-cp312-macosx_10_13_x86_64.whl (293 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.61.1-cp312-cp312-macosx_10_13_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp312-cp312-macosx_10_13_x86_64.whl (66 kB)\n",
      "Downloading pillow-12.0.0-cp312-cp312-macosx_10_13_x86_64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.3.1-py3-none-any.whl (121 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [matplotlib]7\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.61.1 kiwisolver-1.4.9 matplotlib-3.10.8 pillow-12.0.0 pyparsing-3.3.1\n",
      "Installing seaborn>=0.11.0...\n",
      "Collecting seaborn>=0.11.0\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.12/site-packages (from seaborn>=0.11.0) (2.4.0)\n",
      "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.12/site-packages (from seaborn>=0.11.0) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.12/site-packages (from seaborn>=0.11.0) (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=1.2->seaborn>=0.11.0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn>=0.11.0) (1.17.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n",
      "Installing plotnine>=0.8.0...\n",
      "Collecting plotnine>=0.8.0\n",
      "  Downloading plotnine-0.15.2-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: matplotlib>=3.8.0 in ./.venv/lib/python3.12/site-packages (from plotnine>=0.8.0) (3.10.8)\n",
      "Requirement already satisfied: pandas>=2.2.0 in ./.venv/lib/python3.12/site-packages (from plotnine>=0.8.0) (2.3.3)\n",
      "Collecting mizani~=0.14.0 (from plotnine>=0.8.0)\n",
      "  Downloading mizani-0.14.3-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in ./.venv/lib/python3.12/site-packages (from plotnine>=0.8.0) (2.4.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from plotnine>=0.8.0) (1.16.3)\n",
      "Collecting statsmodels>=0.14.5 (from plotnine>=0.8.0)\n",
      "  Downloading statsmodels-0.14.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.12/site-packages (from matplotlib>=3.8.0->plotnine>=0.8.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.0->plotnine>=0.8.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas>=2.2.0->plotnine>=0.8.0) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.8.0->plotnine>=0.8.0) (1.17.0)\n",
      "Collecting patsy>=0.5.6 (from statsmodels>=0.14.5->plotnine>=0.8.0)\n",
      "  Downloading patsy-1.0.2-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading plotnine-0.15.2-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mizani-0.14.3-py3-none-any.whl (133 kB)\n",
      "Downloading statsmodels-0.14.6-cp312-cp312-macosx_10_13_x86_64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.2-py2.py3-none-any.whl (233 kB)\n",
      "Installing collected packages: patsy, statsmodels, mizani, plotnine\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [plotnine]3/4\u001b[0m [plotnine]ls]\n",
      "\u001b[1A\u001b[2KSuccessfully installed mizani-0.14.3 patsy-1.0.2 plotnine-0.15.2 statsmodels-0.14.6\n",
      "Installing requests>=2.25.0...\n",
      "Collecting requests>=2.25.0\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.25.0)\n",
      "  Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.25.0)\n",
      "  Downloading idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.25.0)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.25.0)\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp312-cp312-macosx_10_13_universal2.whl (208 kB)\n",
      "Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Installing collected packages: urllib3, idna, charset_normalizer, certifi, requests\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [requests]2/5\u001b[0m [charset_normalizer]\n",
      "\u001b[1A\u001b[2KSuccessfully installed certifi-2025.11.12 charset_normalizer-3.4.4 idna-3.11 requests-2.32.5 urllib3-2.6.2\n",
      "Installing gdown>=4.0.0...\n",
      "Collecting gdown>=4.0.0\n",
      "  Downloading gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting beautifulsoup4 (from gdown>=4.0.0)\n",
      "  Downloading beautifulsoup4-4.14.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting filelock (from gdown>=4.0.0)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests[socks] in ./.venv/lib/python3.12/site-packages (from gdown>=4.0.0) (2.32.5)\n",
      "Collecting tqdm (from gdown>=4.0.0)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting soupsieve>=1.6.1 (from beautifulsoup4->gdown>=4.0.0)\n",
      "  Downloading soupsieve-2.8.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.12/site-packages (from beautifulsoup4->gdown>=4.0.0) (4.15.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests[socks]->gdown>=4.0.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests[socks]->gdown>=4.0.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests[socks]->gdown>=4.0.0) (2.6.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests[socks]->gdown>=4.0.0) (2025.11.12)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6 (from requests[socks]->gdown>=4.0.0)\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading gdown-5.2.0-py3-none-any.whl (18 kB)\n",
      "Downloading beautifulsoup4-4.14.3-py3-none-any.whl (107 kB)\n",
      "Downloading soupsieve-2.8.1-py3-none-any.whl (36 kB)\n",
      "Downloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, soupsieve, PySocks, filelock, beautifulsoup4, gdown\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [gdown]32m3/6\u001b[0m [filelock]\n",
      "\u001b[1A\u001b[2KSuccessfully installed PySocks-1.7.1 beautifulsoup4-4.14.3 filelock-3.20.1 gdown-5.2.0 soupsieve-2.8.1 tqdm-4.67.1\n",
      "✓ tqdm>=4.62.0 already installed\n",
      "✓ Local CogModelingRNNsTutorial package already installed\n",
      "\n",
      "Setup complete! Please restart the kernel after installation.\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup Cell\n",
    "# If you're seeing import errors, run this cell first to install required packages\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# Required packages\n",
    "packages = [\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"pandas>=1.3.0\", \n",
    "    \"scipy>=1.7.0\",\n",
    "    \"jax>=0.4.0\",\n",
    "    \"jaxlib>=0.4.0\",\n",
    "    \"dm-haiku>=0.0.10\",\n",
    "    \"optax>=0.1.4\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"plotnine>=0.8.0\",\n",
    "    \"requests>=2.25.0\",\n",
    "    \"gdown>=4.0.0\",\n",
    "    \"tqdm>=4.62.0\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.split('>=')[0].split('[')[0])\n",
    "        print(f\"✓ {package} already installed\")\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        install_package(package)\n",
    "\n",
    "# Install local package\n",
    "try:\n",
    "    from CogModelingRNNsTutorial import hybrnn\n",
    "    print(\"✓ Local CogModelingRNNsTutorial package already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing local CogModelingRNNsTutorial package...\")\n",
    "    install_package(\"-e ./CogModelingRNNsTutorial/\")\n",
    "\n",
    "print(\"\\nSetup complete! Please restart the kernel after installation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Notebook for BiControlRNN Model\n",
    "\n",
    "This notebook tests the new learnable gated hybrid architecture of the BiControlRNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX devices: [CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# JAX and Haiku imports\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "\n",
    "# Local imports\n",
    "from CogModelingRNNsTutorial import bandits\n",
    "from CogModelingRNNsTutorial import hybrnn\n",
    "from CogModelingRNNsTutorial import rnn_utils\n",
    "from CogModelingRNNsTutorial import plotting\n",
    "\n",
    "# Set up random seed\n",
    "rng_seq = hk.PRNGSequence(np.random.randint(2**32))\n",
    "\n",
    "print(f\"JAX devices: {jax.devices()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded successfully!\n",
      "xs.shape: (60, 206, 2)\n",
      "ys.shape: (60, 206, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load one of the datasets (e.g., Qasim dataset)\n",
    "import requests\n",
    "from io import StringIO\n",
    "\n",
    "# Download Qasim dataset\n",
    "osf_url = 'https://osf.io/xe6yu/download?direct=1'\n",
    "response = requests.get(osf_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    qasim_data = pd.read_csv(StringIO(response.text))\n",
    "    print('Dataset downloaded successfully!')\n",
    "else:\n",
    "    print('Failed to download dataset')\n",
    "\n",
    "# Prepare data\n",
    "selected_columns = ['participant', 'trials_gamble', 'gamble', 'prob', 'reward']\n",
    "qasim = qasim_data[selected_columns]\n",
    "qasim_filtered = qasim[qasim['trials_gamble'].notna()]\n",
    "qasim_sorted = qasim_filtered.groupby('participant', group_keys=False).apply(lambda x: x.sort_values('trials_gamble'))\n",
    "qasim_sorted = qasim_sorted.reset_index(drop=True)\n",
    "qasim_sorted['participant'] = qasim_sorted.groupby(['participant']).ngroup() + 1\n",
    "qasim_sorted['action'] = qasim_sorted['gamble']\n",
    "\n",
    "# Fill missing actions\n",
    "qasim_sorted['action'] = qasim_sorted['action'].fillna(-1).astype(int)\n",
    "\n",
    "# Generate next action\n",
    "qasim_sorted['action_n'] = (\n",
    "    qasim_sorted\n",
    "    .groupby('participant')['action']\n",
    "    .shift(-1)\n",
    ")\n",
    "last_idxs = qasim_sorted.groupby('participant').tail(1).index\n",
    "qasim_sorted.loc[last_idxs, 'action_n'] = -1\n",
    "\n",
    "# Create sequences\n",
    "xs_list, ys_list = [], []\n",
    "for pid, grp in qasim_sorted.groupby('participant'):\n",
    "    grp = grp.sort_values('trials_gamble')\n",
    "    x = grp[['prob', 'reward']].to_numpy().astype(float)\n",
    "    y = grp[['action_n']].to_numpy().astype(int)\n",
    "    xs_list.append(x)\n",
    "    ys_list.append(y)\n",
    "\n",
    "# Stack into arrays\n",
    "xs = np.stack(xs_list, axis=1)  # (n_trials, n_sessions, 2)\n",
    "ys = np.stack(ys_list, axis=1)  # (n_trials, n_sessions, 1)\n",
    "\n",
    "print(f\"xs.shape: {xs.shape}\")\n",
    "print(f\"ys.shape: {ys.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model parameters\n",
    "rl_params = {\n",
    "    's': True,        # Use state feedback\n",
    "    'o': True,        # Use output feedback\n",
    "    'w_h': 0.5,       # Habit weight\n",
    "    'w_v': 0.5,       # Value weight\n",
    "    'forget': 0.1,    # Forget rate\n",
    "    'fit_forget': False  # Don't fit forget parameter\n",
    "}\n",
    "\n",
    "network_params = {\n",
    "    'n_actions': 2,           # Number of actions\n",
    "    'hidden_size': 64         # Hidden layer size\n",
    "}\n",
    "\n",
    "print(\"Model parameters defined:\")\n",
    "print(f\"RL params: {rl_params}\")\n",
    "print(f\"Network params: {network_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BiControlRNN_model(rl_params, network_params):\n",
    "    \"\"\"BiControlRNN model with learnable gated hybrid architecture.\"\"\"\n",
    "    model = hybrnn.BiControlRNN(rl_params, network_params)\n",
    "    \n",
    "    def forward(xs):\n",
    "        # xs shape: (batch_size, sequence_length, input_dim)\n",
    "        batch_size = xs.shape[0]\n",
    "        \n",
    "        # Initialize hidden state\n",
    "        initial_state = model.initial_state(batch_size)\n",
    "        \n",
    "        # Unroll the RNN\n",
    "        outputs, final_state = hk.dynamic_unroll(\n",
    "            model, xs, initial_state\n",
    "        )\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    return forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters defined:\n",
      "RL params: {'s': True, 'o': True, 'w_h': 0.5, 'w_v': 0.5, 'forget': 0.1, 'fit_forget': False}\n",
      "Network params: {'n_actions': 2, 'hidden_size': 64, 'gate_hidden_size': 32}\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "rl_params = {\n",
    "    's': True,        # Use state feedback\n",
    "    'o': True,        # Use output feedback\n",
    "    'w_h': 0.5,       # Habit weight\n",
    "    'w_v': 0.5,       # Value weight\n",
    "    'forget': 0.1,    # Forget rate\n",
    "    'fit_forget': False  # Don't fit forget parameter\n",
    "}\n",
    "\n",
    "network_params = {\n",
    "    'n_actions': 2,           # Number of actions\n",
    "    'hidden_size': 64,        # Hidden layer size\n",
    "    'gate_hidden_size': 32    # Gate MLP hidden size\n",
    "}\n",
    "\n",
    "print(\"Model parameters defined:\")\n",
    "print(f\"RL params: {rl_params}\")\n",
    "print(f\"Network params: {network_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train sessions: 164\n",
      "Test sessions: 42\n",
      "Train dataset shape: (60, 164, 2)\n",
      "Test dataset shape: (60, 42, 2)\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/test\n",
    "n_sessions = xs.shape[1]\n",
    "train_sessions = int(0.8 * n_sessions)\n",
    "test_sessions = n_sessions - train_sessions\n",
    "\n",
    "# Randomly shuffle sessions\n",
    "session_indices = np.random.permutation(n_sessions)\n",
    "train_idx = session_indices[:train_sessions]\n",
    "test_idx = session_indices[train_sessions:]\n",
    "\n",
    "# Create train/test datasets\n",
    "xs_train = xs[:, train_idx, :]\n",
    "ys_train = ys[:, train_idx, :]\n",
    "xs_test = xs[:, test_idx, :]\n",
    "ys_test = ys[:, test_idx, :]\n",
    "\n",
    "# Create DatasetRNN objects\n",
    "dataset_train = rnn_utils.DatasetRNN(xs_train, ys_train, batch_size=32)\n",
    "dataset_test = rnn_utils.DatasetRNN(xs_test, ys_test, batch_size=32)\n",
    "\n",
    "print(f\"Train sessions: {train_sessions}\")\n",
    "print(f\"Test sessions: {test_sessions}\")\n",
    "print(f\"Train dataset shape: {xs_train.shape}\")\n",
    "print(f\"Test dataset shape: {xs_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot concatenate arrays with shapes that differ in dimensions other than the one being concatenated: concatenating along dimension 1 for shapes (32, 1), (32, 2), (60, 2), (60, 64).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m xs_batch, ys_batch = \u001b[38;5;28mnext\u001b[39m(dataset_train)\n\u001b[32m      6\u001b[39m rng_key = \u001b[38;5;28mnext\u001b[39m(rng_seq)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m params = \u001b[43mmodel_fun\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel initialized with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(p.size\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mp\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mjax.tree_util.tree_leaves(params))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m parameters\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/transform.py:166\u001b[39m, in \u001b[36mwithout_state.<locals>.init_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minit_fn\u001b[39m(*args, **kwargs) -> hk.MutableParams:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m   params, state = \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[32m    168\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m base.NonEmptyStateError(\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIf your transformed function uses `hk.\u001b[39m\u001b[33m{\u001b[39m\u001b[33mget,set}_state` then use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`hk.transform_with_state`.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/transform.py:424\u001b[39m, in \u001b[36mtransform_with_state.<locals>.init_fn\u001b[39m\u001b[34m(rng, *args, **kwargs)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m base.new_context(rng=rng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[32m    423\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    425\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m jax.errors.UnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m jax.errors.UnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(xs)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Transform model function\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model_fun = hk.transform(\u001b[38;5;28;01mlambda\u001b[39;00m xs: \u001b[43mBiControlRNN_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrl_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnetwork_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialize parameters\u001b[39;00m\n\u001b[32m      5\u001b[39m xs_batch, ys_batch = \u001b[38;5;28mnext\u001b[39m(dataset_train)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mBiControlRNN_model.<locals>.forward\u001b[39m\u001b[34m(xs)\u001b[39m\n\u001b[32m     10\u001b[39m initial_state = model.initial_state(batch_size)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Unroll the RNN\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m outputs, final_state = \u001b[43mhk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdynamic_unroll\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/recurrent.py:204\u001b[39m, in \u001b[36mdynamic_unroll\u001b[39m\u001b[34m(core, input_sequence, initial_state, time_major, reverse, return_all_states, unroll)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m time_major:\n\u001b[32m    202\u001b[39m   input_sequence = _swap_batch_time(input_sequence)\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m scan_result = \u001b[43mscan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscan_f\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munroll\u001b[49m\u001b[43m=\u001b[49m\u001b[43munroll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_all_states:\n\u001b[32m    207\u001b[39m   _, (output_sequence, state_sequence) = scan_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/stateful.py:615\u001b[39m, in \u001b[36mscan\u001b[39m\u001b[34m(f, init, xs, length, reverse, unroll)\u001b[39m\n\u001b[32m    613\u001b[39m   x0 = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m0\u001b[39m], xs)\n\u001b[32m    614\u001b[39m   xs = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[32m1\u001b[39m:], xs)\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m init, y0 = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m y0 = jax.tree.map(\u001b[38;5;28;01mlambda\u001b[39;00m y: jnp.expand_dims(y, \u001b[32m0\u001b[39m), y0)\n\u001b[32m    617\u001b[39m length -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/recurrent.py:195\u001b[39m, in \u001b[36mdynamic_unroll.<locals>.scan_f\u001b[39m\u001b[34m(prev_state, inputs)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mscan_f\u001b[39m(prev_state, inputs):\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m   outputs, next_state = \u001b[43mcore\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m return_all_states:\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m next_state, (outputs, next_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/module.py:464\u001b[39m, in \u001b[36mwrap_method.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    461\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m method_name != \u001b[33m\"\u001b[39m\u001b[33m__call__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    462\u001b[39m     f = jax.named_call(f, name=method_name)\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m out = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/module.py:305\u001b[39m, in \u001b[36mrun_interceptors\u001b[39m\u001b[34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m ctx = MethodContext(module=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    308\u001b[39m                     method_name=method_name,\n\u001b[32m    309\u001b[39m                     orig_method=bound_method,\n\u001b[32m    310\u001b[39m                     orig_class=orig_class)\n\u001b[32m    311\u001b[39m interceptor_stack_copy = interceptor_stack.clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/CogModelingRNNsTutorial/hybrnn.py:225\u001b[39m, in \u001b[36mBiControlRNN.__call__\u001b[39m\u001b[34m(self, inputs, prev_state)\u001b[39m\n\u001b[32m    222\u001b[39m action_onehot = jax.nn.one_hot(action,\u001b[32m2\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# Value module: update/create new values\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m225\u001b[39m next_value, next_v_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_value_rnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_onehot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[38;5;66;03m# Habit module: update/create new habit\u001b[39;00m\n\u001b[32m    228\u001b[39m next_habit, next_h_state = \u001b[38;5;28mself\u001b[39m._habit_rnn(h_state, habit, action_onehot, value, reward)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/module.py:464\u001b[39m, in \u001b[36mwrap_method.<locals>.wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    461\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m method_name != \u001b[33m\"\u001b[39m\u001b[33m__call__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    462\u001b[39m     f = jax.named_call(f, name=method_name)\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m out = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[32m    467\u001b[39m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[32m    468\u001b[39m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[32m    469\u001b[39m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/Cellar/python@3.12/3.12.2_1/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:81\u001b[39m, in \u001b[36mContextDecorator.__call__.<locals>.inner\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minner\u001b[39m(*args, **kwds):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._recreate_cm():\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/haiku/_src/module.py:305\u001b[39m, in \u001b[36mrun_interceptors\u001b[39m\u001b[34m(bound_method, method_name, self, orig_class, *args, **kwargs)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m ctx = MethodContext(module=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    308\u001b[39m                     method_name=method_name,\n\u001b[32m    309\u001b[39m                     orig_method=bound_method,\n\u001b[32m    310\u001b[39m                     orig_class=orig_class)\n\u001b[32m    311\u001b[39m interceptor_stack_copy = interceptor_stack.clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/CogModelingRNNsTutorial/hybrnn.py:147\u001b[39m, in \u001b[36mBiControlRNN._value_rnn\u001b[39m\u001b[34m(self, state, value, action, reward)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03mLearnable Gated Hybrid Value RNN.\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    142\u001b[39m \u001b[33;03m- Memory Stream: Slow, state-driven processing\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;66;03m# 1. Learnable Gate (The Arbitrator)\u001b[39;00m\n\u001b[32m    146\u001b[39m \u001b[38;5;66;03m# Inputs: reward, action, prev_value, prev_state\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m gate_inputs = \u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# (B, 1)\u001b[39;49;00m\n\u001b[32m    149\u001b[39m \u001b[43m    \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\u001b[38;5;66;43;03m# (B, n_actions)\u001b[39;49;00m\n\u001b[32m    150\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                   \u001b[49m\u001b[38;5;66;43;03m# (B, n_actions)\u001b[39;49;00m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# (B, hidden_size)\u001b[39;49;00m\n\u001b[32m    152\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[38;5;66;03m# Gate MLP: Linear -> ReLU -> Linear -> Sigmoid\u001b[39;00m\n\u001b[32m    155\u001b[39m gate_hidden = jax.nn.relu(\u001b[38;5;28mself\u001b[39m._gate_mlp_layer1(gate_inputs))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/numpy/lax_numpy.py:4788\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(arrays, axis, dtype)\u001b[39m\n\u001b[32m   4786\u001b[39m k = \u001b[32m16\u001b[39m\n\u001b[32m   4787\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(arrays_out) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m4788\u001b[39m   arrays_out = [\u001b[43mlax\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays_out\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4789\u001b[39m                 \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(arrays_out), k)]\n\u001b[32m   4790\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_out[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:673\u001b[39m, in \u001b[36mconcatenate\u001b[39m\u001b[34m(operands, dimension)\u001b[39m\n\u001b[32m    671\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(op, Array):\n\u001b[32m    672\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m op\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate_p\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43moperands\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdimension\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/core.py:463\u001b[39m, in \u001b[36mPrimitive.bind\u001b[39m\u001b[34m(self, *args, **params)\u001b[39m\n\u001b[32m    461\u001b[39m trace_ctx.set_trace(eval_trace)\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m463\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    465\u001b[39m   trace_ctx.set_trace(prev_trace)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/core.py:468\u001b[39m, in \u001b[36mPrimitive.bind_with_trace\u001b[39m\u001b[34m(self, trace, args, params)\u001b[39m\n\u001b[32m    467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/core.py:941\u001b[39m, in \u001b[36mEvalTrace.process_primitive\u001b[39m\u001b[34m(self, primitive, args, params)\u001b[39m\n\u001b[32m    939\u001b[39m       \u001b[38;5;28;01mreturn\u001b[39;00m primitive.bind_with_trace(arg._trace, args, params)\n\u001b[32m    940\u001b[39m check_eval_args(args)\n\u001b[32m--> \u001b[39m\u001b[32m941\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/dispatch.py:90\u001b[39m, in \u001b[36mapply_primitive\u001b[39m\u001b[34m(prim, *args, **params)\u001b[39m\n\u001b[32m     88\u001b[39m prev = lib.jax_jit.swap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m   outs = \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     92\u001b[39m   lib.jax_jit.swap_thread_local_state_disable_jit(prev)\n",
      "    \u001b[31m[... skipping hidden 20 frame]\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DeepMind_project/CogModelingRNNsTutorial/.venv/lib/python3.12/site-packages/jax/_src/lax/lax.py:4453\u001b[39m, in \u001b[36m_concatenate_shape_rule\u001b[39m\u001b[34m(*operands, **kwargs)\u001b[39m\n\u001b[32m   4449\u001b[39m   msg = (\u001b[33m\"\u001b[39m\u001b[33mCannot concatenate arrays with shapes that differ in dimensions \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4450\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mother than the one being concatenated: concatenating along \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4451\u001b[39m          \u001b[33m\"\u001b[39m\u001b[33mdimension \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m for shapes \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4452\u001b[39m   shapes = [operand.shape \u001b[38;5;28;01mfor\u001b[39;00m operand \u001b[38;5;129;01min\u001b[39;00m operands]\n\u001b[32m-> \u001b[39m\u001b[32m4453\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg.format(dimension, \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, shapes))))\n\u001b[32m   4455\u001b[39m concat_size = \u001b[38;5;28msum\u001b[39m(o.shape[dimension] \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m operands)\n\u001b[32m   4456\u001b[39m ex_shape = operands[\u001b[32m0\u001b[39m].shape\n",
      "\u001b[31mTypeError\u001b[39m: Cannot concatenate arrays with shapes that differ in dimensions other than the one being concatenated: concatenating along dimension 1 for shapes (32, 1), (32, 2), (60, 2), (60, 64)."
     ]
    }
   ],
   "source": [
    "# Transform model function\n",
    "model_fun = hk.transform(lambda xs: BiControlRNN_model(rl_params, network_params)(xs))\n",
    "\n",
    "# Initialize parameters\n",
    "xs_batch, ys_batch = next(dataset_train)\n",
    "rng_key = next(rng_seq)\n",
    "params = model_fun.init(rng_key, xs_batch)\n",
    "\n",
    "print(f\"Model initialized with {sum(p.size for p in jax.tree_util.tree_leaves(params))} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"Training BiControlRNN model...\")\n",
    "\n",
    "trained_params, train_losses = rnn_utils.fit_model(\n",
    "    model_fun=model_fun,\n",
    "    dataset_train=dataset_train,\n",
    "    dataset_test=dataset_test,\n",
    "    loss_fun='categorical',\n",
    "    optimizer=optax.adam(learning_rate=1e-3),\n",
    "    n_steps_per_call=100,\n",
    "    n_steps_max=5000,\n",
    "    early_stop_step=100,\n",
    "    if_early_stop=True\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed. Final loss: {train_losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log likelihood on test set\n",
    "print(\"\\nEvaluating model on test set...\")\n",
    "mean_ll, std_ll = compute_log_likelihood(dataset_test, model_fun, trained_params)\n",
    "\n",
    "print(f\"Test set normalized likelihood: {100 * mean_ll:.1f}% ± {100 * std_ll:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Analyze Gate Behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract gate signals during model execution\n",
    "def BiControlRNN_with_gate_analysis(rl_params, network_params):\n",
    "    \"\"\"Modified BiControlRNN that returns gate signals for analysis.\"\"\"\n",
    "    \n",
    "    class BiControlRNNWithGates(hybrnn.BiControlRNN):\n",
    "        def __call__(self, inputs, prev_state):\n",
    "            # Call parent method\n",
    "            logits, next_state = super().__call__(inputs, prev_state)\n",
    "            \n",
    "            # Extract gate signal from value module\n",
    "            h_state, v_state, habit, value = prev_state\n",
    "            action_onehot = jax.nn.one_hot(inputs[:, 0].astype(int), self._n_actions)\n",
    "            reward = inputs[:, -1]\n",
    "            \n",
    "            # Calculate gate inputs\n",
    "            gate_inputs = jnp.concatenate([\n",
    "                reward[:, jnp.newaxis],\n",
    "                action_onehot,\n",
    "                value,\n",
    "                v_state\n",
    "            ], axis=-1)\n",
    "            \n",
    "            # Get gate signal\n",
    "            gate_hidden = jax.nn.relu(self._gate_mlp_layer1(gate_inputs))\n",
    "            gate_signal = jax.nn.sigmoid(self._gate_mlp_layer2(gate_hidden))\n",
    "            \n",
    "            return logits, next_state, gate_signal\n",
    "    \n",
    "    model = BiControlRNNWithGates(rl_params, network_params)\n",
    "    \n",
    "    def forward(xs):\n",
    "        batch_size = xs.shape[0]\n",
    "        initial_state = model.initial_state(batch_size)\n",
    "        \n",
    "        # Custom unroll to capture gate signals\n",
    "        def step(carry, x):\n",
    "            state = carry\n",
    "            logits, next_state, gate_signal = model(x, state)\n",
    "            return next_state, (logits, gate_signal)\n",
    "        \n",
    "        _, (outputs, gate_signals) = hk.scan(\n",
    "            step, initial_state, xs\n",
    "        )\n",
    "        \n",
    "        return outputs, gate_signals\n",
    "    \n",
    "    return forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze gate behavior on a test batch\n",
    "model_with_gates = hk.transform(lambda xs: BiControlRNN_with_gate_analysis(rl_params, network_params)(xs))\n",
    "\n",
    "# Get a test batch\n",
    "xs_test_batch, ys_test_batch = next(dataset_test)\n",
    "\n",
    "# Run model with gate analysis\n",
    "outputs, gate_signals = model_with_gates.apply(trained_params, rng_key, xs_test_batch)\n",
    "\n",
    "print(f\"Gate signals shape: {gate_signals.shape}\")\n",
    "print(f\"Mean gate signal: {gate_signals.mean():.3f}\")\n",
    "print(f\"Gate signal std: {gate_signals.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot gate signals over time\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot 1: Gate signals over trials for a few sessions\n",
    "plt.subplot(1, 2, 1)\n",
    "for i in range(min(5, gate_signals.shape[1])):\n",
    "    plt.plot(gate_signals[:, i, 0], label=f'Session {i+1}', alpha=0.7)\n",
    "plt.xlabel('Trial')\n",
    "plt.ylabel('Gate Signal')\n",
    "plt.title('Gate Signals Over Time')\n",
    "plt.legend()\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "# Plot 2: Gate signal distribution\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(gate_signals.flatten(), bins=50, alpha=0.7, density=True)\n",
    "plt.xlabel('Gate Signal')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Gate Signal Distribution')\n",
    "plt.xlim([0, 1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('Training Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.yscale('log')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Compare with Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a baseline BiRNN (without learnable gates) for comparison\n",
    "def BiRNN_baseline_model(rl_params, network_params):\n",
    "    \"\"\"Baseline BiRNN model.\"\"\"\n",
    "    model = hybrnn.BiRNN(rl_params, network_params)\n",
    "    \n",
    "    def forward(xs):\n",
    "        batch_size = xs.shape[0]\n",
    "        initial_state = model.initial_state(batch_size)\n",
    "        outputs, _ = hk.dynamic_unroll(model, xs, initial_state)\n",
    "        return outputs\n",
    "    \n",
    "    return forward\n",
    "\n",
    "# Train baseline\n",
    "baseline_model_fun = hk.transform(lambda xs: BiRNN_baseline_model(rl_params, network_params)(xs))\n",
    "baseline_params = baseline_model_fun.init(rng_key, xs_batch)\n",
    "\n",
    "print(\"Training baseline BiRNN...\")\n",
    "baseline_trained_params, baseline_losses = rnn_utils.fit_model(\n",
    "    model_fun=baseline_model_fun,\n",
    "    dataset_train=dataset_train,\n",
    "    dataset_test=dataset_test,\n",
    "    loss_fun='categorical',\n",
    "    optimizer=optax.adam(learning_rate=1e-3),\n",
    "    n_steps_per_call=100,\n",
    "    n_steps_max=5000,\n",
    "    early_stop_step=100,\n",
    "    if_early_stop=True\n",
    ")\n",
    "\n",
    "# Evaluate baseline\n",
    "baseline_mean_ll, baseline_std_ll = compute_log_likelihood(dataset_test, baseline_model_fun, baseline_trained_params)\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"BiControlRNN (learnable gates): {100 * mean_ll:.1f}% ± {100 * std_ll:.1f}%\")\n",
    "print(f\"BiRNN (baseline):            {100 * baseline_mean_ll:.1f}% ± {100 * baseline_std_ll:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "1. **Learnable Gate Architecture**: The BiControlRNN model learns to dynamically arbitrate between context and memory streams\n",
    "2. **Gate Analysis**: We can extract and visualize the gate signals to understand how the model balances fast vs. slow learning\n",
    "3. **Performance Comparison**: The learnable gated model can be compared against baseline models\n",
    "\n",
    "The key innovation is that the model learns *when* to rely on immediate context (high gate signal) vs. historical memory (low gate signal), rather than using hardcoded RPE-based weighting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
